/* forward propagation
 * Multiply - add process
 * Dot Product
 * Forward Propagation for one data point at a time 
 * Output is the prediction fo that data point
 */

/*forward propagation code*/
import numpy as np 
input_data = np.array([2,3])
weights = {'node_0':np.array([1,1]),
           'node_1':np.array([-1,1]),
           'output':np.array([2,-1])}

node_0_value = (input_data * weights['node_0']).sum()
node_1_value = (input_data * weights['node_1']).sum()

hidden_layer_values = np.array([node_0_value,node_1_value])
print(hidden_layer_values) 

output = (hidden_layer_values * weights['output']).sum()
print(output)

/*activation functions*/
/*Activation Functions:
 *For neural networks to achieve their maximum predictive power
 *we apply an activation function in the hidden layers.
 
 *An activation function is something applied to the value coming into a node,
 *which then transforms it into the value stored in that node, or the node output
 */

/*ReLU (REctified Linear Activation)
 *this function returns 0 if input is negative
 *this function returns absolute value of input if input is positive
 */

/*define the relu function below: */
def relu(input):
    '''Define your relu activation function here'''
    # Calculate the value for the output of the relu function: output
    output = max(input, 0)
    
    # Return the value just calculated
    return(output)

# Calculate node 0 value: node_0_output
node_0_input = (input_data * weights['node_0']).sum()
node_0_output = relu(node_0_input)

# Calculate node 1 value: node_1_output
node_1_input = (input_data * weights['node_1']).sum()
node_1_output = relu(node_1_input)

# Put node values into array: hidden_layer_outputs
hidden_layer_outputs = np.array([node_0_output, node_1_output])

# Calculate model output (do not apply relu)
model_output = (hidden_layer_outputs * weights['output']).sum()

# Print model output
print(model_output)


/*forward propagation with activation function*/
import numpy as np
input_data = np.array([-1,2])
weights = {'node_0':np.array([3,3]),
           'node_1':np.array([1,5]),
           'output':np.array([2,-1])}

/*the difference here is that we distinguish the input from output*/
node_0_input = (input_data *weights['node_0']).sum()
node_0_output = np.tanh(node_0_input)

node_1_input = (input_data *weights['node_1']).sum()
node_1_output = np.tanh(node_1_input)

hidden_layer_values = np.array([node_0_value,node_1_value])
output = (hidden_layer_values * weights['output']).sum()

/*we use the activation function to transfer the input into output*/
# Define predict_with_network()
def predict_with_network(input_data_row, weights):

    # Calculate node 0 value
    node_0_input = (input_data_row *weights['node_0']).sum()
    node_0_output = relu(node_0_input)

    # Calculate node 1 value
    node_1_input = (input_data_row *weights['node_1']).sum()
    node_1_output = relu(node_1_input)

    # Put node values into array: hidden_layer_outputs
    hidden_layer_outputs = np.array([node_0_output, node_1_output])
    
    # Calculate model output
    input_to_final_layer = (hidden_layer_outputs * weights['output']).sum()
    model_output = relu(input_to_final_layer)
    
    # Return model output
    return(model_output)

# Create empty list to store prediction results
results = []
for input_data_row in input_data:
    # Append prediction to results
    results.append(predict_with_network(input_data_row, weights))

# Print results
print(results)     


/*deeper networks*/
/*calculate with ReLU Activation Function*/
/*remember that if the result is negative, you should return 0*/

/*deep learning == representation learning*/
/*deep learning
 *modeler doesn not need to specify the interactions
 *when you train the model, the neural network get weigths
 *that find the relevant patterns to make better predictions
 */
def predict_with_network(input_data):
    # Calculate node 0 in the first hidden layer
    node_0_0_input = (input_data* weights['node_0_0']).sum()
    node_0_0_output = relu(node_0_0_input)

    # Calculate node 1 in the first hidden layer
    node_0_1_input = (input_data* weights['node_0_1']).sum()
    node_0_1_output = relu(node_0_1_input)

    # Put node values into array: hidden_0_outputs
    hidden_0_outputs = np.array([node_0_0_output, node_0_1_output])
    
    # Calculate node 0 in the second hidden layer
    node_1_0_input = (hidden_0_outputs* weights['node_1_0']).sum()
    node_1_0_output = relu(node_1_0_input)

    # Calculate node 1 in the second hidden layer
    node_1_1_input = (hidden_0_outputs* weights['node_1_1']).sum()
    node_1_1_output = relu(node_1_1_input)

    # Put node values into array: hidden_1_outputs
    hidden_1_outputs = np.array([node_1_0_output, node_1_1_output])

    # Calculate model output: model_output
    model_output = (hidden_1_outputs * weights['output']).sum()
    
    # Return model_output
    return(model_output)

output = predict_with_network(input_data)
print(output)



